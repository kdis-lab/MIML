/*    This program is free software; you can redistribute it and/or modify
 *    it under the terms of the GNU General Public License as published by
 *    the Free Software Foundation; either version 2 of the License, or
 *    (at your option) any later version.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    GNU General Public License for more details.
 *
 *    You should have received a copy of the GNU General Public License
 *    along with this program; if not, write to the Free Software
 *    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */
package miml.evaluation;

import java.io.File;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;
import java.util.concurrent.TimeUnit;
import org.apache.commons.configuration2.Configuration;
import miml.classifiers.miml.IMIMLClassifier;
import miml.data.MIMLInstances;
import miml.transformation.mimlTOml.MIMLtoML;
import miml.classifiers.miml.mimlTOml.MIMLClassifierToML;
import mulan.classifier.clus.ClusWrapperClassification;
import mulan.data.InvalidDataFormatException;
import mulan.data.MultiLabelInstances;
import mulan.evaluation.Evaluator;
import mulan.evaluation.measure.AveragePrecision;
import mulan.evaluation.measure.Coverage;
import mulan.evaluation.measure.ErrorSetSize;
import mulan.evaluation.measure.ExampleBasedAccuracy;
import mulan.evaluation.measure.ExampleBasedFMeasure;
import mulan.evaluation.measure.ExampleBasedPrecision;
import mulan.evaluation.measure.ExampleBasedRecall;
import mulan.evaluation.measure.ExampleBasedSpecificity;
import mulan.evaluation.measure.GeometricMeanAverageInterpolatedPrecision;
import mulan.evaluation.measure.GeometricMeanAveragePrecision;
import mulan.evaluation.measure.HammingLoss;
import mulan.evaluation.measure.IsError;
import mulan.evaluation.measure.LogLoss;
import mulan.evaluation.measure.MacroFMeasure;
import mulan.evaluation.measure.MacroPrecision;
import mulan.evaluation.measure.MacroRecall;
import mulan.evaluation.measure.MacroSpecificity;
import mulan.evaluation.measure.MeanAverageInterpolatedPrecision;
import mulan.evaluation.measure.MeanAveragePrecision;
import mulan.evaluation.measure.Measure;
import mulan.evaluation.measure.MicroFMeasure;
import mulan.evaluation.measure.MicroPrecision;
import mulan.evaluation.measure.MicroRecall;
import mulan.evaluation.measure.MicroSpecificity;
import mulan.evaluation.measure.OneError;
import mulan.evaluation.measure.RankingLoss;
import mulan.evaluation.measure.SubsetAccuracy;
import weka.core.Instances;
import weka.filters.Filter;
import weka.filters.unsupervised.attribute.Remove;

/**
 * Class that allow evaluate a classifier applying a holdout method with the
 * clus System. NOTE that that RFPCT calls clus library that performs, in a
 * single call, train and test steps. Therefore:
 * 1. Train time got by miml library is not relevant.
 * 2. Test time got by miml libraryr really computes the train and test time
 * required by the call to clus library.
 *
 * @author Eva Gibaja
 * @version 20230117
 */
public class EvaluatorHoldoutClus extends EvaluatorHoldout {

	/**
	 * The directory where all temporary files needed or generated by CLUS library
	 * are written.
	 */
	protected String clusWorkingDir;

	/** The dataset name that will be used for training, test and settings files. */
	protected String clusDatasetName;

	/**
	 * Instantiates a new holdout evaluator with provided train and test partitions.
	 *
	 * @param trainData       The train data used in the experiment.
	 * @param testData        The test data used in the experiment.
	 * @param clusDatasetName The dataset name that will be used for training, test
	 *                        and settings files.
	 * @param clusWorkingDir  The directory where all temporary files needed or
	 *                        generated by CLUS library are written.
	 * @throws InvalidDataFormatException To be handled.
	 */
	public EvaluatorHoldoutClus(MIMLInstances trainData, MIMLInstances testData, String clusWorkingDir,
			String clusDatasetName) throws InvalidDataFormatException {
		super(trainData, testData);
		this.clusWorkingDir = clusWorkingDir + File.separator;
		this.clusDatasetName = clusDatasetName;
	}

	/**
	 * No-argument constructor for xml configuration.
	 */
	public EvaluatorHoldoutClus() {
	}

	/*
	 * (non-Javadoc)
	 * 
	 * @see evaluation.IEvaluator#runExperiment(mimlclassifier.MIMLClassifier)
	 */
	@Override
	public void runExperiment(IMIMLClassifier classifier) {

		System.out.println("" + new Date() + ": " + "Building model");
		try {

			/*
			 * Step 1. The build method on the MIMLClassifierToML transforms the MIML
			 * dataset into a ML dataset an calls the build method of RFPCT. The build
			 * method of RFPCT transforms the transformed ML data into an arff formated file
			 * (accepted by CLUS) and write the -train.arff file in the working directory
			 * with the appropriate name. Nevertheless the RFPCT model itself is not built
			 * as the clus library performs in the same step the train and test. For this
			 * reason train time is not representative.
			 */

			long startTime = System.nanoTime();
			((MIMLClassifierToML) classifier).build(trainData);
			long estimatedTime = System.nanoTime() - startTime;
			trainTime = TimeUnit.NANOSECONDS.toMillis(estimatedTime);

			/* Step 2. The MIML test data is transformed to ML. */

			MIMLtoML transformationMethod = ((MIMLClassifierToML) classifier).getTransformationMethod();
			Remove removeFilter = ((MIMLClassifierToML) classifier).getRemoveFilter();
			MultiLabelInstances testDataML = transformationMethod.transformDataset(testData);
			Instances newData = Filter.useFilter(testDataML.getDataSet(), removeFilter);
			testData = new MIMLInstances(newData, testData.getLabelsMetaData());

			/*
			 * Step 3. The call to eval.evaluate(ClusWrapperClassification learner,
			 * MultiLabelInstances testData, List<Measure> measures) 1) writes the
			 * transformed ML test data in the -test.arff in the working directory and then
			 * the call to clus library performs both train and test stages. The test time
			 * computed corresponds to the time required by clus to perform train and test.
			 */
			System.out.println("" + new Date() + ": " + "Getting evaluation results");
			startTime = System.nanoTime();
			Evaluator eval = new Evaluator();
			List<Measure> measures = this.prepareMeasuresClassification(trainData);

			// The evaluate method expects the clusWorkingDir with a final File.separator
			// i.e. clusFolder\. Due to this reason, the constructor and configure methods
			// add a File.separator to the clusWorkingDir
			evaluation = eval.evaluate(
					(ClusWrapperClassification) (((MIMLClassifierToML) classifier).getBaseClassifier()), testData,
					measures);

			estimatedTime = System.nanoTime() - startTime;
			testTime = TimeUnit.NANOSECONDS.toMillis(estimatedTime);

		} catch (Exception e) {
			e.printStackTrace();
		}
	}

	/*
	 * @see
	 * core.IConfiguration#configure(org.apache.commons.configuration.Configuration)
	 */
	@Override
	public void configure(Configuration configuration) {

		super.configure(configuration);

		clusWorkingDir = configuration.getString("clusWorkingDir", "clusFolder") + File.separator;
		clusDatasetName = configuration.getString("clusDataset", "dataset");


	}

	protected List<Measure> prepareMeasuresClassification(MultiLabelInstances mlTrainData) {
		List<Measure> measures = new ArrayList<Measure>();

		int numOfLabels = mlTrainData.getNumLabels();

		// add example-based measures
		measures.add((Measure) new HammingLoss());
		// measures.add(new AdjHammingLoss());
		measures.add(new SubsetAccuracy());
		measures.add(new ExampleBasedPrecision());
		measures.add(new ExampleBasedRecall());
		measures.add(new ExampleBasedFMeasure());
		measures.add(new ExampleBasedAccuracy());
		measures.add(new ExampleBasedSpecificity());

		// add label-based measures
		measures.add(new MicroPrecision(numOfLabels));
		measures.add(new MicroRecall(numOfLabels));
		measures.add(new MicroFMeasure(numOfLabels));
		measures.add(new MicroSpecificity(numOfLabels));
		measures.add(new MacroPrecision(numOfLabels));
		measures.add(new MacroRecall(numOfLabels));
		measures.add(new MacroFMeasure(numOfLabels));
		measures.add(new MacroSpecificity(numOfLabels));

		// add ranking based measures
		measures.add(new AveragePrecision());
		measures.add(new Coverage());
		measures.add(new OneError());
		measures.add(new IsError());
		measures.add(new ErrorSetSize());
		measures.add(new RankingLoss());

		// add confidence measures if applicable
		measures.add(new MeanAveragePrecision(numOfLabels));
		measures.add(new GeometricMeanAveragePrecision(numOfLabels));
		measures.add(new MeanAverageInterpolatedPrecision(numOfLabels, 10));
		measures.add(new GeometricMeanAverageInterpolatedPrecision(numOfLabels, 10));
		// measures.add(new MicroAUC(numOfLabels));
		// measures.add(new MacroAUC(numOfLabels));
		measures.add(new LogLoss());

		return measures;
	}
}